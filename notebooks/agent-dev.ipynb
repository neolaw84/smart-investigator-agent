{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getenv\n",
    "\n",
    "from uuid import uuid4\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  api_key=getenv(\"OPENAI_API_KEY\"),\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "llm.invoke(input=[SystemMessage(content=\"You are a helpful assistant\"), HumanMessage(content=\"Hi, help me with coding.\")], config={\"configurable\": {\"thread_id\": str(uuid4()) }})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "import random\n",
    "\n",
    "from typing import Literal, Optional, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain.tools import tool\n",
    "\n",
    "from langgraph.checkpoint.base import BaseCheckpointSaver\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_core.messages import AnyMessage, ToolMessage, SystemMessage, AIMessage, HumanMessage\n",
    "\n",
    "from langgraph.types import interrupt, Command\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"get_weather\", description=\"Get the current weather in a given location as string.\")\n",
    "def get_weather(location):\n",
    "    weather = random.choice([\"sunny\", \"rainy\"])\n",
    "    return f\"The weather in {location} is {weather}.\"\n",
    "\n",
    "@tool(\"ask_for_help\", description=\"Ask for help from the caller agent (usually human).\")\n",
    "def ask_for_help(question):\n",
    "    help = interrupt(f\"I have a question : {question}\")\n",
    "    return help \n",
    "\n",
    "@tool(\"ask_for_help_tkt\", description=\"Ask for help from the caller agent (usually travel agent).\")\n",
    "def ask_for_help_tkt(question):\n",
    "    help = interrupt(f\"I have a question : {question}\")\n",
    "    return help \n",
    "\n",
    "@tool(\"calculate_total\", description=\"Calculate the total amount from quantity and unit price.\")\n",
    "def calculate_total(quantity: int, unit_price: float) -> float:\n",
    "    return quantity * unit_price\n",
    "\n",
    "@tool(\"check_ticket_price\", description=\"Check the price of a ticket for a given origin, destination and whether it is round-trip or one-way.\")\n",
    "def check_ticket_price(origin: str, destination: str, round_trip: bool) -> float:\n",
    "    base_price = 100.0\n",
    "    if round_trip:\n",
    "        return base_price * 2\n",
    "    return base_price\n",
    "\n",
    "class TravelAgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    loop_counter: int\n",
    "\n",
    "class TicketingAgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    loop_counter: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ticketing_agent(llm: BaseChatModel, checkpointer: BaseCheckpointSaver):\n",
    "    MAX_LOOPS = 3\n",
    "    tools = [ask_for_help_tkt, calculate_total, check_ticket_price]\n",
    "    tool_name_to_executables = {tool.name: tool for tool in tools}\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "    def llm_call(state: TicketingAgentState) -> TicketingAgentState:\n",
    "        if state.get(\"loop_counter\", 0) > MAX_LOOPS:\n",
    "            state[\"messages\"] = [AIMessage(content=\"It seems I am going around. Goodbye!\")]\n",
    "            return state\n",
    "\n",
    "        _input = [SystemMessage(\"You are a ticketing agent. \\\n",
    "                                You can help calculate the total ticket price. And print invoice.\"\n",
    "                            )] + \\\n",
    "                 state[\"messages\"]\n",
    "\n",
    "        ai_message = llm_with_tools.invoke(\n",
    "                input=_input\n",
    "            )\n",
    "        state[\"messages\"] = [ai_message]\n",
    "        state[\"loop_counter\"] = 1 + state.get(\"loop_counter\", 0)\n",
    "        return state\n",
    "\n",
    "    def check_tool_call(state: TicketingAgentState) -> Literal[\"tool_executor\", \"END\"]:\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if last_message.tool_calls:\n",
    "            return \"tool_executor\"\n",
    "        else:\n",
    "            return END\n",
    "\n",
    "    def tool_executor(state: TicketingAgentState):\n",
    "        result = []\n",
    "        for tc in state[\"messages\"][-1].tool_calls:\n",
    "            _id, _name, _args = tc[\"id\"], tc[\"name\"], tc[\"args\"]\n",
    "            tool_response = tool_name_to_executables[_name].invoke(_args)\n",
    "            result.append(ToolMessage(content=tool_response, tool_call_id=_id))\n",
    "        state[\"messages\"].extend(result)\n",
    "        return state\n",
    "\n",
    "    builder = StateGraph(TicketingAgentState)\n",
    "    builder.add_node(\"llm_call\", llm_call)\n",
    "    builder.add_node(\"tool_executor\", tool_executor)\n",
    "    builder.add_edge(START, \"llm_call\")\n",
    "    builder.add_conditional_edges(\"llm_call\", check_tool_call, [\"tool_executor\", END])\n",
    "    builder.add_edge(\"tool_executor\", \"llm_call\")\n",
    "\n",
    "    return builder.compile(checkpointer=checkpointer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ticketing_llm = ChatOpenAI(\n",
    "  api_key=getenv(\"OPENAI_API_KEY\"),\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "user_inputs = [\n",
    "    \"I want to go to Bali, Indonesia. 2 tickets.\",\n",
    "    \"Sydney, Australia. Round-trip please. \",\n",
    "    \"yes. Proceed and invpoice me\",\n",
    "    \"...\",\n",
    "    \"exit\",\n",
    "    \"exit\"\n",
    "]\n",
    "input_iter = iter(user_inputs)\n",
    "\n",
    "greeting = \"Hi! I'm your ticketing assistant. How can I help you today?\\n\"\n",
    "print (greeting)\n",
    "config={\"configurable\": {\"thread_id\": str(uuid4()) }}\n",
    "agent_tkt = create_ticketing_agent(ticketing_llm, InMemorySaver())\n",
    "while True:    \n",
    "    content = next(input_iter) # input(\"Your response (or 'exit' to quit): \")\n",
    "    if content.lower() in ['exit', 'quit']:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    human_message = HumanMessage(content=content)\n",
    "    human_message.pretty_print()\n",
    "    response = agent_tkt.invoke({\"messages\": [human_message], \"loop_counter\": 0}, config=config)\n",
    "    while \"__interrupt__\" in response:\n",
    "        response[\"messages\"][-1].pretty_print()\n",
    "        human_response = next(input_iter) # input (str(response[\"messages\"][-1].content) + \"\\nYour response: \")\n",
    "        response = agent_tkt.invoke(Command(resume=response), config=config)\n",
    "\n",
    "    response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain.tools import InjectedToolCallId, ToolRuntime\n",
    "from langgraph.types import Command\n",
    "\n",
    "\n",
    "@tool(\n",
    "    \"ticketing_agent_tool\",\n",
    "    description=\"A tool for interacting with the ticketing agent. \\\n",
    "        Use this tool to delegate ticketing-related queries to the ticketing agent. \\\n",
    "        Make sure you provide what you have to the agent (e.g., number of tickets, \\\n",
    "        round trip or one way, origin and destination) so it has the full context.\",\n",
    ")\n",
    "# We need to pass the `tool_call_id` to the sub agent so it can use it to respond with the tool call result\n",
    "def agent_tkt_tool(\n",
    "    query: str, \n",
    "    # tool_call_id: Annotated[str, InjectedToolCallId],\n",
    "# You need to return a `Command` object to include more than just a final tool call\n",
    ") -> str:\n",
    "    result = agent_tkt.invoke({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": query}]\n",
    "    })\n",
    "    while \"__interrupt__\" in result:\n",
    "        human_response = interrupt(\"Ticketing Agent has a question: \\n\" + str(result[\"messages\"][-1].content) + \"\\nYour response: \")\n",
    "        _config = {\"configurable\": {\"thread_id\": str(uuid4()) }}\n",
    "        result = agent_tkt.invoke(Command(resume=human_response), config=_config)\n",
    "    return result[\"messages\"][-1].content\n",
    "    # return Command(update={\n",
    "    #     # This is the example state key we are passing back\n",
    "    #     # \"example_state_key\": result[\"example_state_key\"],\n",
    "    #     \"messages\": [\n",
    "    #         ToolMessage(\n",
    "    #             content=result[\"messages\"][-1].content,\n",
    "    #             # We need to include the tool call id so it matches up with the right tool call\n",
    "    #             tool_call_id=tool_call_id\n",
    "    #         )\n",
    "    #     ]\n",
    "    # })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.language_models import BaseChatModel\n",
    "from langgraph.checkpoint.base import BaseCheckpointSaver\n",
    "\n",
    "def create_travel_agent(llm: BaseChatModel, checkpointer: BaseCheckpointSaver):\n",
    "    tools = [get_weather, ask_for_help, agent_tkt_tool]\n",
    "    tool_name_to_executables = {tool.name: tool for tool in tools}\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    MAX_LOOPS = 3\n",
    "    def llm_call(state: TravelAgentState) -> TravelAgentState:\n",
    "        if state.get(\"loop_counter\", 0) > MAX_LOOPS:\n",
    "            state[\"messages\"] = [AIMessage(content=\"It seems I am going around. Goodbye!\")]\n",
    "            return state\n",
    "\n",
    "        _input = [SystemMessage(\"You are a travel agent. You can help the caller check weather information. You can also recommend hotels.\")] + \\\n",
    "                 state[\"messages\"]\n",
    "\n",
    "        ai_message = llm_with_tools.invoke(\n",
    "                input=_input\n",
    "            )\n",
    "        state[\"messages\"] = [ai_message]\n",
    "        state[\"loop_counter\"] = 1 + state.get(\"loop_counter\", 0)\n",
    "        return state\n",
    "\n",
    "    def check_tool_call(state: TravelAgentState) -> Literal[\"tool_executor\", \"END\"]:\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if last_message.tool_calls:\n",
    "            return \"tool_executor\"\n",
    "        else:\n",
    "            return END\n",
    "\n",
    "    def tool_executor(state: TravelAgentState):\n",
    "        result = []\n",
    "        for tc in state[\"messages\"][-1].tool_calls:\n",
    "            _id, _name, _args = tc[\"id\"], tc[\"name\"], tc[\"args\"]\n",
    "            tool_response = tool_name_to_executables[_name].invoke(_args)\n",
    "            result.append(ToolMessage(content=tool_response, tool_call_id=_id))\n",
    "        state[\"messages\"].extend(result)\n",
    "        return state\n",
    "\n",
    "    builder = StateGraph(TravelAgentState)\n",
    "    builder.add_node(\"llm_call\", llm_call)\n",
    "    builder.add_node(\"tool_executor\", tool_executor)\n",
    "    builder.add_edge(START, \"llm_call\")\n",
    "    builder.add_conditional_edges(\"llm_call\", check_tool_call, [\"tool_executor\", END])\n",
    "    builder.add_edge(\"tool_executor\", \"llm_call\")\n",
    "\n",
    "    return builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_inputs = [\n",
    "    \"I want to go to Bali. For 2 adults. Next week Wednesday.\",\n",
    "    \"Departing from Sydney Australia, 30th November return. Nothing else. \",\n",
    "    \"yes, proceed with the booking\",\n",
    "    \"ok,\",\n",
    "    \"exit\",\n",
    "    \"exit\"\n",
    "]\n",
    "input_iter = iter(user_inputs)\n",
    "\n",
    "llm_travel = ChatOpenAI(\n",
    "  api_key=getenv(\"OPENAI_API_KEY\"),\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "greeting = \"Hi! I'm your travel assistant. How can I help you today?\\n\"\n",
    "print (greeting)\n",
    "config={\"configurable\": {\"thread_id\": str(uuid4()) }}\n",
    "agent = create_travel_agent(llm_travel, InMemorySaver())\n",
    "while True:    \n",
    "    content = next(input_iter) # input(\"Your response (or 'exit' to quit):\") # next(input_iter) # input(\"Your response (or 'exit' to quit): \")\n",
    "    if content.lower() in ['exit', 'quit']:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    human_message = HumanMessage(content=content)\n",
    "    human_message.pretty_print()\n",
    "    response = agent.invoke({\"messages\": [human_message], \"loop_counter\": 0}, config=config)\n",
    "    while \"__interrupt__\" in response:\n",
    "        response[\"messages\"][-1].pretty_print()\n",
    "        human_response = next(input_iter) # input (str(response[\"messages\"][-1].content) + \"\\nYour response: \")\n",
    "        response = agent.invoke(Command(resume=response), config=config)\n",
    "\n",
    "    response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312-si",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
