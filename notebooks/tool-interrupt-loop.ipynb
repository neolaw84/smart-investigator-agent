{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a55d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "\n",
    "while \"src\" not in os.listdir(): os.chdir(\"..\")\n",
    "\n",
    "if \"./src\" not in sys.path: sys.path.append(\"./src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "618503de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getenv\n",
    "\n",
    "from uuid import uuid4\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  api_key=getenv(\"OPENAI_API_KEY\"),\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  model=\"gpt-4o-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "169b8dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from uuid import uuid4\n",
    "\n",
    "from typing import Annotated, Literal, List, Dict, Optional, Union, TypedDict\n",
    "\n",
    "from langchain.tools import InjectedToolCallId, tool, ToolRuntime\n",
    "\n",
    "from langchain_core.language_models.fake_chat_models import FakeMessagesListChatModel\n",
    "from langchain_core.messages import AIMessage, AnyMessage, ToolMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.messages.tool import tool_call\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "from langgraph.types import Command, interrupt, Send, Interrupt\n",
    "from langgraph.graph import add_messages, StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae7a883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ai_message(msg:str) -> AIMessage:\n",
    "    try:\n",
    "        content = json.loads(msg)\n",
    "        return AIMessage(content=\"calling a tool ... \", tool_calls=[tool_call(**tc) for tc in content])\n",
    "    except:\n",
    "        return AIMessage(content=msg)\n",
    "\n",
    "class FakeMessagesListChatModelWithTools(FakeMessagesListChatModel):\n",
    "    def bind_tools(self, tools:list):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ca04b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "0 Yay yay, nay nay!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "foo\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "1 Yay yay, nay nay!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "bar\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "2 Yay yay, nay nay!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "exit\n"
     ]
    }
   ],
   "source": [
    "ca_responses = [AIMessage(content=f\"{i} Yay yay, nay nay!\") for i in list(range(100))]\n",
    "ca_verbose = True \n",
    "\n",
    "class ChatAgentState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    human_wants_out: bool\n",
    "\n",
    "ca_llm = FakeMessagesListChatModelWithTools(\n",
    "    responses=ca_responses\n",
    ")\n",
    "\n",
    "def ca_llm_node(state: ChatAgentState):\n",
    "    result = ca_llm.invoke(input=state[\"messages\"])\n",
    "    if ca_verbose: result.pretty_print()\n",
    "    return {\"messages\": [result]}\n",
    "\n",
    "def ca_interrupt_node(state: ChatAgentState):\n",
    "    result = interrupt({\"prompt\": str(state[\"messages\"][-1].content)})\n",
    "    human_input_as_str = str(result[\"human_input\"])\n",
    "    human_message = HumanMessage(human_input_as_str)\n",
    "    human_wants_out = human_input_as_str.strip().lower() in (\"exit\", \"quit\")\n",
    "    if ca_verbose: human_message.pretty_print()\n",
    "    return {\n",
    "            \"messages\": [human_message], \n",
    "            \"human_wants_out\": human_wants_out\n",
    "        }\n",
    "\n",
    "def ca_loop_breaker(state: ChatAgentState):\n",
    "    return END if state[\"human_wants_out\"] else \"ca_llm_node\"\n",
    "\n",
    "ca_builder = StateGraph(ChatAgentState)\n",
    "ca_builder.add_node(ca_llm_node, \"ca_llm_node\")\n",
    "ca_builder.add_node(ca_interrupt_node, \"ca_interrupt_node\")\n",
    "ca_builder.add_edge(START, \"ca_llm_node\")\n",
    "ca_builder.add_edge(\"ca_llm_node\", \"ca_interrupt_node\")\n",
    "ca_builder.add_conditional_edges(\"ca_interrupt_node\", ca_loop_breaker)\n",
    "\n",
    "ca = ca_builder.compile(InMemorySaver())\n",
    "\n",
    "ca_config = {\"configurable\": {\"thread_id\": str(uuid4())}}\n",
    "result = {\"messages\": [SystemMessage(\"You say yay or nay.\")], \"human_wants_out\": False}\n",
    "input_iter = iter([\"foo\", \"bar\", \"exit\"])\n",
    "while True:\n",
    "    result = ca.invoke(input=result, config=ca_config)\n",
    "    if \"__interrupt__\" not in result: break \n",
    "    human_input = next(input_iter) # input(result[\"__interrupt__\"][0].value[\"prompt\"])\n",
    "    result = Command(resume={\"human_input\": human_input})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c6fcb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "calling tool ...\n",
      "Tool Calls:\n",
      "  chat_agent_tool (38f7a22b-a996-4b3e-ab18-56fff1b3e190)\n",
      " Call ID: 38f7a22b-a996-4b3e-ab18-56fff1b3e190\n",
      "  Args:\n",
      "    user_message: MA System.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "foo foo\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "bar bar\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "exit\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "ca_verbose = False \n",
    "\n",
    "class MasterAgentState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    ca_says_over: bool\n",
    "\n",
    "def chat_llm_node(state: MasterAgentState):\n",
    "    tc = tool_call(id=str(uuid4()), name=\"chat_agent_tool\", args={\"user_message\": str(state[\"messages\"][-1].content)})\n",
    "    ai_message = AIMessage(content=\"calling tool ... \", tool_calls=[tc])\n",
    "    return {\"messages\": [ai_message], \"ca_says_over\": False}\n",
    "\n",
    "@tool\n",
    "def chat_agent_tool(user_message:str=\"\", resume_data: Union[Dict, str]=\"\", runtime: ToolRuntime=None):\n",
    "    \"\"\"This call the specialized chat agent with user's query. \n",
    "    Put an empty string as resume_data.\"\"\"\n",
    "    if resume_data:\n",
    "        # this resume_data must be superset of resume expected by chat agent\n",
    "        # for fields like \"config\"\n",
    "        human_or_system_message = HumanMessage(resume_data[\"human_input\"])\n",
    "        result = Command(resume={k: v for k, v in resume_data.items() if k != \"config\"}) # subsequent ones\n",
    "        _config = resume_data[\"config\"]\n",
    "    else: \n",
    "        result = {\"messages\": runtime.state[\"messages\"], \"human_wants_out\": False} # first one\n",
    "        _config = {\"configurable\": {\"thread_id\": str(uuid4())}}\n",
    "        human_or_system_message = result[\"messages\"][-1]\n",
    "\n",
    "    result = ca.invoke(result, config=_config)\n",
    "    \n",
    "    human_or_system_message.pretty_print()\n",
    "    tool_message = ToolMessage(\"Success\", tool_call_id=runtime.tool_call_id)\n",
    "    messages = [tool_message, human_or_system_message]\n",
    "    \n",
    "    # this indicates the chat agent is done with chatting (no AIMessage)\n",
    "    if result[\"human_wants_out\"]: return Command(update={\"messages\": messages, \"ca_says_over\": True})\n",
    "\n",
    "    # two possibilities here, interrupt or no interrupt\n",
    "    # since chat agent may not done yet, we need to interrupt regardless\n",
    "    if \"__interrupt__\" in result.keys():\n",
    "        # in this case, there will be no AIMessage as well\n",
    "        interrupt_data = {\"__interrupt__\": result[\"__interrupt__\"][0]}\n",
    "    else:\n",
    "        ai_message = result[\"messages\"][-1]\n",
    "        ai_message.pretty_print()\n",
    "        messages.append(ai_message)\n",
    "        interrupt_data = {\"__interrupt__\": Interrupt({\"prompt\": str(ai_message.content)}), \"id\": str(uuid4())}\n",
    "    \n",
    "    update = {\"messages\": messages}\n",
    "    interrupt_data[\"config\"] = _config\n",
    "\n",
    "    return Command(goto=Send(\"chat_agent_interrupt_node\", arg={\"interrupt_data\": interrupt_data} | update))\n",
    "\n",
    "chat_agent_tool_node = ToolNode(tools=[chat_agent_tool])\n",
    "\n",
    "def chat_agent_interrupt_node(state: MasterAgentState):\n",
    "    interrupt_data = state[\"interrupt_data\"]\n",
    "    human_input = interrupt(interrupt_data[\"__interrupt__\"])\n",
    "    resume_data = {\n",
    "            \"human_input\": human_input,\n",
    "            \"config\": interrupt_data[\"config\"]\n",
    "        }\n",
    "    tc = tool_call(id = str(uuid4()), name=\"chat_agent_tool\", args={\"user_message\": \"\", \"resume_data\": resume_data})\n",
    "    ai_message = AIMessage(content=\"calling tool ... \", tool_calls=[tc]) \n",
    "    # return Command(goto=Send(\"chat_agent_tool_node\", arg={\"state\": {\"messages\": [ai_message]}}), update={\"messages\": [ai_message]})\n",
    "    return Command(goto=\"chat_agent_tool_node\", update={\"messages\": [ai_message]})\n",
    "\n",
    "ma_builder = StateGraph(MasterAgentState)\n",
    "ma_builder.add_node(\"chat_llm_node\", chat_llm_node)\n",
    "ma_builder.add_node(\"chat_agent_tool_node\", chat_agent_tool_node)\n",
    "ma_builder.add_node(\"chat_agent_interrupt_node\", chat_agent_interrupt_node)\n",
    "ma_builder.add_edge(START, \"chat_llm_node\")\n",
    "ma_builder.add_edge(\"chat_llm_node\", \"chat_agent_tool_node\")\n",
    "ma_builder.add_edge(\"chat_agent_tool_node\", END)\n",
    "ma = ma_builder.compile(InMemorySaver())\n",
    "\n",
    "\n",
    "ma_config = {\"configurable\": {\"thread_id\": str(uuid4())}}\n",
    "result = {\"messages\": [SystemMessage(\"MA System.\")], \"ca_says_over\": False}\n",
    "input_iter = iter([\"foo foo\", \"bar bar\", \"exit\"])\n",
    "while True:\n",
    "    result = ma.invoke(input=result, config=ma_config)\n",
    "    if result[\"ca_says_over\"]: break \n",
    "    human_input = next(input_iter) # input(result[\"__interrupt__\"][0].value[\"prompt\"])\n",
    "    result = Command(resume=human_input)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f4f958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "calling tool ...\n",
      "Tool Calls:\n",
      "  chat_agent_tool (21de8d0e-0457-40ef-b9f8-0d15ad54c111)\n",
      " Call ID: 21de8d0e-0457-40ef-b9f8-0d15ad54c111\n",
      "  Args:\n",
      "    user_message: User want to chat.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [SystemMessage(content='User want to chat.', additional_kwargs={}, response_metadata={}, id='557ae29a-b835-4923-b5ce-c10667f5c96a'),\n",
       "  AIMessage(content='calling tool ... ', additional_kwargs={}, response_metadata={}, id='892b6dcd-8d8a-4e1d-bcbf-eb32c1b1ef18', tool_calls=[{'name': 'chat_agent_tool', 'args': {'user_message': 'User want to chat.'}, 'id': '21de8d0e-0457-40ef-b9f8-0d15ad54c111', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content='Success', name='chat_agent_tool', id='a74d6f77-837e-44e3-8350-43f4dd332c99', tool_call_id='21de8d0e-0457-40ef-b9f8-0d15ad54c111')],\n",
       " 'ca_says_over': False,\n",
       " '__interrupt__': [Interrupt(value=Interrupt(value={'prompt': '5 Yay yay, nay nay!'}, id='0dbd6d4fe7e089550a7db8dfae7de88f'), id='c732f8ae3966c968ea963dfebeb2a272')]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_config = {\"configurable\": {\"thread_id\": str(uuid4())}}\n",
    "result = ma.invoke(input={\"messages\": [SystemMessage(\"User want to chat.\")]}, config=ma_config)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9481ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Interrupt(value={'prompt': '11 Yay yay, nay nay!'}, id='1c42bff0584b89abc348a13f5ddd323c')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"__interrupt__\"][0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be080f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca36329",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_conversation = \"\"\"\n",
    "A: Hi, I am a ticketing agent. How can I help you?\n",
    "Q: Hello, I want to go to Bali. Can you help me book a flight?\n",
    "A: [{\"id\": \"tkt_1\", \"name\": \"ask_for_help_tkt\", \"args\": {\"question\": \"From where, Human? Round-trip or one-way?\"}}]\n",
    "Q: From Sydney, Australia. Round-trip. \n",
    "A: [{\"id\": \"tkt_2\", \"name\": \"check_ticket_price\", \"args\": {\"origin\": \"Sydney\", \"destination\": \"Bali\", \"round_trip\": true}}, {\"id\": \"tkt_3\", \"name\": \"ask_for_help_tkt\", \"args\": {\"question\": \"How many heads, Human?\"}}]\n",
    "Q: Just one. How much would it be?\n",
    "A: [{\"id\": \"tkt_4\", \"name\": \"calculate_total\", \"args\": {\"quantity\": 1, \"unit_price\": 1000.99}}]\n",
    "A: It will be $1000.99, ok to proceed?\n",
    "Q: Yes, please book the flight.\n",
    "A: Great! Your flight from Sydney to Bali has been booked. Safe travels!\n",
    "Q: exit\n",
    "\"\"\"\n",
    "\n",
    "human_questions = [qim[3:] for qim in example_conversation.split(\"\\n\") if qim.startswith(\"Q: \") or len(qim.strip())==0]\n",
    "ai_responses = [aim[3:] for aim in example_conversation.split(\"\\n\") if aim.startswith(\"A: \")]\n",
    "\n",
    "responses=[create_ai_message(msg) for msg in ai_responses]\n",
    "\n",
    "fake_model = FakeMessagesListChatModelWithTools(\n",
    "    responses=responses\n",
    ")\n",
    "\n",
    "# ticketing_agent = create_ticketing_agent(fake_model, InMemorySaver(), agent_tools=[])\n",
    "\n",
    "# input_iter = iter(human_questions)\n",
    "# config={\"configurable\": {\"thread_id\": str(uuid4()) }}\n",
    "# while True:    \n",
    "#     content = next(input_iter) # input(\"Your response (or 'exit' to quit): \")\n",
    "#     human_message = HumanMessage(content=content)\n",
    "#     human_message.pretty_print()\n",
    "#     if content.lower() in ['exit', 'quit']:\n",
    "#         AIMessage(content=\"Goodbye!\").pretty_print()\n",
    "#         break\n",
    "#     response = ticketing_agent.invoke({\"messages\": [human_message], \"loop_counter\": 0}, config=config)\n",
    "#     while \"__interrupt__\" in response:\n",
    "#         print (\"in interrupt\")\n",
    "#         response[\"messages\"][-1].pretty_print()\n",
    "#         human_response = next(input_iter) # input (str(response[\"messages\"][-1].content) + \"\\nYour response: \")\n",
    "#         HumanMessage(content=human_response).pretty_print()\n",
    "#         response = ticketing_agent.invoke(Command(resume=response), config=config)\n",
    "\n",
    "#     response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a6655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from uuid import uuid4\n",
    "from typing import Annotated\n",
    "from langchain.tools import InjectedToolCallId\n",
    "# from langchain_core.tools import tool\n",
    "from langchain.tools import ToolRuntime, tool\n",
    "from langchain_core.messages import HumanMessage, AnyMessage, SystemMessage, ToolMessage\n",
    "from langgraph.types import Command, interrupt, Send\n",
    "from langgraph.graph import add_messages\n",
    "from typing import Literal\n",
    "\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
